# Data Processing Workflow

We are provided with the video (Youtube links) and audio (in mp3 format) extracted from the video.  The transcript of courtroom proceedings, prepared by [TERES](https://teres.ai/) is provided in a pdf format. The transcript has proper speaker annotation, but no timestamps.

The task is to preprocess the speech and audio data into a format suitable for ASR training. This involves aligning the speech data with the transcript so that the audio can be sliced into smaller chunks <= 20s with associated transcripts.

The minimal requirement is to have a dataset in the following format



| Filepath   | Transcript                                                 |
| ---------- | ---------------------------------------------------------- |
| audio1.wav | That can be postponed, their putting it up on the website. |
| audio2.wav | Fair enough. No objection                                  |

A better processing pipeline would be to include some additional information like (For later):\
\


<table><thead><tr><th>Filepath</th><th>Speaker</th><th>Transcript</th><th data-type="number">Duration (s)</th></tr></thead><tbody><tr><td>audio1.wav</td><td>JDYC</td><td>That can be postponed, their putting it up on the website.</td><td>2.3</td></tr><tr><td>audio2.wav</td><td>KS</td><td>Fair Enough. No objection</td><td>1.1</td></tr></tbody></table>



### Text Processing Pipeline

The proceedings report generated by TERES is in pdf format.
